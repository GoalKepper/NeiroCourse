{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv-dHdZ_9Wof"
      },
      "source": [
        "# Advanced model implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKZX9KBP9bKU"
      },
      "source": [
        "Instead of using just models from scikit, we were looking for more advanced and powerfull solution of problems, firts of all, we tried out to implement several models like `BaggingClassifier` or `HistGradientBoostingClassifier`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siKtCab19yjc"
      },
      "source": [
        "They were good, unitl we reached `0.908` roof of the possible power, so with reworking of base models, we start using updating dataset with more advanced model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spffh5kV-hqd"
      },
      "outputs": [],
      "source": [
        "import random as rn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier,\\\n",
        "                             BaggingClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMZM5Xjo-lxq"
      },
      "source": [
        "After base libs, we start to updating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OoT4RYR9Tjo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://gitlab.com/MaskedTrench/csv-database/-/raw/main/dataset.csv', sep = ',')\n",
        "df = df.fillna(0)\n",
        "\n",
        "df['rto'] = df[['rto_6','rto_7', 'rto_8', 'rto_9', 'rto_10', 'rto_11', 'rto_12']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_6','rto_7', 'rto_8', 'rto_9', 'rto_10', 'rto_11', 'rto_12'])\n",
        "df['rto_std'] = df[['rto_std_6','rto_std_7', 'rto_std_8', 'rto_std_9', 'rto_std_10', 'rto_std_11', 'rto_std_12']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_std_6','rto_std_7', 'rto_std_8', 'rto_std_9', 'rto_std_10', 'rto_std_11', 'rto_std_12'])\n",
        "df['cnt_checks'] = df[['cnt_checks_6','cnt_checks_7', 'cnt_checks_8', 'cnt_checks_9', 'cnt_checks_10', 'cnt_checks_11', 'cnt_checks_12']].sum(axis=1)\n",
        "df = df.drop(columns=['cnt_checks_6','cnt_checks_7', 'cnt_checks_8', 'cnt_checks_9', 'cnt_checks_10', 'cnt_checks_11', 'cnt_checks_12'])\n",
        "\n",
        "df['rto_Крупы и зерновые'] = df[['rto_6_Крупы и зерновые','rto_7_Крупы и зерновые', 'rto_8_Крупы и зерновые', 'rto_9_Крупы и зерновые', 'rto_10_Крупы и зерновые', 'rto_11_Крупы и зерновые', 'rto_12_Крупы и зерновые']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_6_Крупы и зерновые','rto_7_Крупы и зерновые', 'rto_8_Крупы и зерновые', 'rto_9_Крупы и зерновые', 'rto_10_Крупы и зерновые', 'rto_11_Крупы и зерновые', 'rto_12_Крупы и зерновые'])\n",
        "df['rto_Мясная гастрономия'] = df[['rto_6_Мясная гастрономия','rto_7_Мясная гастрономия', 'rto_8_Мясная гастрономия', 'rto_9_Мясная гастрономия', 'rto_10_Мясная гастрономия', 'rto_11_Мясная гастрономия', 'rto_12_Мясная гастрономия']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_6_Мясная гастрономия','rto_7_Мясная гастрономия', 'rto_8_Мясная гастрономия', 'rto_9_Мясная гастрономия', 'rto_10_Мясная гастрономия', 'rto_11_Мясная гастрономия', 'rto_12_Мясная гастрономия'])\n",
        "df['rto_Овощи - Фрукты'] = df[['rto_6_Овощи - Фрукты','rto_7_Овощи - Фрукты', 'rto_8_Овощи - Фрукты', 'rto_9_Овощи - Фрукты', 'rto_10_Овощи - Фрукты', 'rto_11_Овощи - Фрукты', 'rto_12_Овощи - Фрукты']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_6_Овощи - Фрукты','rto_7_Овощи - Фрукты', 'rto_8_Овощи - Фрукты', 'rto_9_Овощи - Фрукты', 'rto_10_Овощи - Фрукты', 'rto_11_Овощи - Фрукты', 'rto_12_Овощи - Фрукты'])\n",
        "df['rto_Птица и изделия из птицы'] = df[['rto_6_Птица и изделия из птицы','rto_7_Птица и изделия из птицы', 'rto_8_Птица и изделия из птицы', 'rto_9_Птица и изделия из птицы', 'rto_10_Птица и изделия из птицы', 'rto_11_Птица и изделия из птицы', 'rto_12_Птица и изделия из птицы']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_6_Птица и изделия из птицы','rto_7_Птица и изделия из птицы', 'rto_8_Птица и изделия из птицы', 'rto_9_Птица и изделия из птицы', 'rto_10_Птица и изделия из птицы', 'rto_11_Птица и изделия из птицы', 'rto_12_Птица и изделия из птицы'])\n",
        "df['rto_Рыба и рыбные изделия'] = df[['rto_6_Рыба и рыбные изделия','rto_7_Рыба и рыбные изделия', 'rto_8_Рыба и рыбные изделия', 'rto_9_Рыба и рыбные изделия', 'rto_10_Рыба и рыбные изделия', 'rto_11_Рыба и рыбные изделия', 'rto_12_Рыба и рыбные изделия']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_6_Рыба и рыбные изделия','rto_7_Рыба и рыбные изделия', 'rto_8_Рыба и рыбные изделия', 'rto_9_Рыба и рыбные изделия', 'rto_10_Рыба и рыбные изделия', 'rto_11_Рыба и рыбные изделия', 'rto_12_Рыба и рыбные изделия'])\n",
        "df['rto_Сыры'] = df[['rto_6_Сыры','rto_7_Сыры', 'rto_8_Сыры', 'rto_9_Сыры', 'rto_10_Сыры', 'rto_11_Сыры', 'rto_12_Сыры']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_6_Сыры','rto_7_Сыры', 'rto_8_Сыры', 'rto_9_Сыры', 'rto_10_Сыры', 'rto_11_Сыры', 'rto_12_Сыры'])\n",
        "\n",
        "df['rto_stddev_Крупы и зерновые'] = df[['rto_stddev_6_Крупы и зерновые','rto_stddev_7_Крупы и зерновые', 'rto_stddev_8_Крупы и зерновые', 'rto_stddev_9_Крупы и зерновые', 'rto_stddev_10_Крупы и зерновые', 'rto_stddev_11_Крупы и зерновые', 'rto_stddev_12_Крупы и зерновые']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_stddev_6_Крупы и зерновые','rto_stddev_7_Крупы и зерновые', 'rto_stddev_8_Крупы и зерновые', 'rto_stddev_9_Крупы и зерновые', 'rto_stddev_10_Крупы и зерновые', 'rto_stddev_11_Крупы и зерновые', 'rto_stddev_12_Крупы и зерновые'])\n",
        "df['rto_stddev_Мясная гастрономия'] = df[['rto_stddev_6_Мясная гастрономия','rto_stddev_7_Мясная гастрономия', 'rto_stddev_8_Мясная гастрономия', 'rto_stddev_9_Мясная гастрономия', 'rto_stddev_10_Мясная гастрономия', 'rto_stddev_11_Мясная гастрономия', 'rto_stddev_12_Мясная гастрономия']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_stddev_6_Мясная гастрономия','rto_stddev_7_Мясная гастрономия', 'rto_stddev_8_Мясная гастрономия', 'rto_stddev_9_Мясная гастрономия', 'rto_stddev_10_Мясная гастрономия', 'rto_stddev_11_Мясная гастрономия', 'rto_stddev_12_Мясная гастрономия'])\n",
        "df['rto_stddev_Овощи - Фрукты'] = df[['rto_stddev_6_Овощи - Фрукты','rto_stddev_7_Овощи - Фрукты', 'rto_stddev_8_Овощи - Фрукты', 'rto_stddev_9_Овощи - Фрукты', 'rto_stddev_10_Овощи - Фрукты', 'rto_stddev_11_Овощи - Фрукты', 'rto_stddev_12_Овощи - Фрукты']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_stddev_6_Овощи - Фрукты','rto_stddev_7_Овощи - Фрукты', 'rto_stddev_8_Овощи - Фрукты', 'rto_stddev_9_Овощи - Фрукты', 'rto_stddev_10_Овощи - Фрукты', 'rto_stddev_11_Овощи - Фрукты', 'rto_stddev_12_Овощи - Фрукты'])\n",
        "df['rto_stddev_Птица и изделия из птицы'] = df[['rto_stddev_6_Птица и изделия из птицы','rto_stddev_7_Птица и изделия из птицы', 'rto_stddev_8_Птица и изделия из птицы', 'rto_stddev_9_Птица и изделия из птицы', 'rto_stddev_10_Птица и изделия из птицы', 'rto_stddev_11_Птица и изделия из птицы', 'rto_stddev_12_Птица и изделия из птицы']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_stddev_6_Птица и изделия из птицы','rto_stddev_7_Птица и изделия из птицы', 'rto_stddev_8_Птица и изделия из птицы', 'rto_stddev_9_Птица и изделия из птицы', 'rto_stddev_10_Птица и изделия из птицы', 'rto_stddev_11_Птица и изделия из птицы', 'rto_stddev_12_Птица и изделия из птицы'])\n",
        "df['rto_stddev_Рыба и рыбные изделия'] = df[['rto_stddev_6_Рыба и рыбные изделия','rto_stddev_7_Рыба и рыбные изделия', 'rto_stddev_8_Рыба и рыбные изделия', 'rto_stddev_9_Рыба и рыбные изделия', 'rto_stddev_10_Рыба и рыбные изделия', 'rto_stddev_11_Рыба и рыбные изделия', 'rto_stddev_12_Рыба и рыбные изделия']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_stddev_6_Рыба и рыбные изделия','rto_stddev_7_Рыба и рыбные изделия', 'rto_stddev_8_Рыба и рыбные изделия', 'rto_stddev_9_Рыба и рыбные изделия', 'rto_stddev_10_Рыба и рыбные изделия', 'rto_stddev_11_Рыба и рыбные изделия', 'rto_stddev_12_Рыба и рыбные изделия'])\n",
        "df['rto_stddev_Сыры'] = df[['rto_stddev_6_Сыры','rto_stddev_7_Сыры', 'rto_stddev_8_Сыры', 'rto_stddev_9_Сыры', 'rto_stddev_10_Сыры', 'rto_stddev_11_Сыры', 'rto_stddev_12_Сыры']].sum(axis=1)\n",
        "df = df.drop(columns=['rto_stddev_6_Сыры','rto_stddev_7_Сыры', 'rto_stddev_8_Сыры', 'rto_stddev_9_Сыры', 'rto_stddev_10_Сыры', 'rto_stddev_11_Сыры', 'rto_stddev_12_Сыры'])\n",
        "\n",
        "df['cnt_checks_Крупы и зерновые'] = df[['cnt_checks_6_Крупы и зерновые','cnt_checks_7_Крупы и зерновые', 'cnt_checks_8_Крупы и зерновые', 'cnt_checks_9_Крупы и зерновые', 'cnt_checks_10_Крупы и зерновые', 'cnt_checks_11_Крупы и зерновые', 'cnt_checks_12_Крупы и зерновые']].sum(axis=1)\n",
        "df = df.drop(columns=['cnt_checks_6_Крупы и зерновые','cnt_checks_7_Крупы и зерновые', 'cnt_checks_8_Крупы и зерновые', 'cnt_checks_9_Крупы и зерновые', 'cnt_checks_10_Крупы и зерновые', 'cnt_checks_11_Крупы и зерновые', 'cnt_checks_12_Крупы и зерновые'])\n",
        "df['cnt_checks_Мясная гастрономия'] = df[['cnt_checks_6_Мясная гастрономия','cnt_checks_7_Мясная гастрономия', 'cnt_checks_8_Мясная гастрономия', 'cnt_checks_9_Мясная гастрономия', 'cnt_checks_10_Мясная гастрономия', 'cnt_checks_11_Мясная гастрономия', 'cnt_checks_12_Мясная гастрономия']].sum(axis=1)\n",
        "df = df.drop(columns=['cnt_checks_6_Мясная гастрономия','cnt_checks_7_Мясная гастрономия', 'cnt_checks_8_Мясная гастрономия', 'cnt_checks_9_Мясная гастрономия', 'cnt_checks_10_Мясная гастрономия', 'cnt_checks_11_Мясная гастрономия', 'cnt_checks_12_Мясная гастрономия'])\n",
        "df['cnt_checks_Овощи - Фрукты'] = df[['cnt_checks_6_Овощи - Фрукты','cnt_checks_7_Овощи - Фрукты', 'cnt_checks_8_Овощи - Фрукты', 'cnt_checks_9_Овощи - Фрукты', 'cnt_checks_10_Овощи - Фрукты', 'cnt_checks_11_Овощи - Фрукты', 'cnt_checks_12_Овощи - Фрукты']].sum(axis=1)\n",
        "df = df.drop(columns=['cnt_checks_6_Овощи - Фрукты','cnt_checks_7_Овощи - Фрукты', 'cnt_checks_8_Овощи - Фрукты', 'cnt_checks_9_Овощи - Фрукты', 'cnt_checks_10_Овощи - Фрукты', 'cnt_checks_11_Овощи - Фрукты', 'cnt_checks_12_Овощи - Фрукты'])\n",
        "df['cnt_checks_Птица и изделия из птицы'] = df[['cnt_checks_6_Птица и изделия из птицы','cnt_checks_7_Птица и изделия из птицы', 'cnt_checks_8_Птица и изделия из птицы', 'cnt_checks_9_Птица и изделия из птицы', 'cnt_checks_10_Птица и изделия из птицы', 'cnt_checks_11_Птица и изделия из птицы', 'cnt_checks_12_Птица и изделия из птицы']].sum(axis=1)\n",
        "df = df.drop(columns=['cnt_checks_6_Птица и изделия из птицы','cnt_checks_7_Птица и изделия из птицы', 'cnt_checks_8_Птица и изделия из птицы', 'cnt_checks_9_Птица и изделия из птицы', 'cnt_checks_10_Птица и изделия из птицы', 'cnt_checks_11_Птица и изделия из птицы', 'cnt_checks_12_Птица и изделия из птицы'])\n",
        "df['cnt_checks_Рыба и рыбные изделия'] = df[['cnt_checks_6_Рыба и рыбные изделия','cnt_checks_7_Рыба и рыбные изделия', 'cnt_checks_8_Рыба и рыбные изделия', 'cnt_checks_9_Рыба и рыбные изделия', 'cnt_checks_10_Рыба и рыбные изделия', 'cnt_checks_11_Рыба и рыбные изделия', 'cnt_checks_12_Рыба и рыбные изделия']].sum(axis=1)\n",
        "df = df.drop(columns=['cnt_checks_6_Рыба и рыбные изделия','cnt_checks_7_Рыба и рыбные изделия', 'cnt_checks_8_Рыба и рыбные изделия', 'cnt_checks_9_Рыба и рыбные изделия', 'cnt_checks_10_Рыба и рыбные изделия', 'cnt_checks_11_Рыба и рыбные изделия', 'cnt_checks_12_Рыба и рыбные изделия'])\n",
        "df['cnt_checks_Сыры'] = df[['cnt_checks_6_Сыры','cnt_checks_7_Сыры', 'cnt_checks_8_Сыры', 'cnt_checks_9_Сыры', 'cnt_checks_10_Сыры', 'cnt_checks_11_Сыры', 'cnt_checks_12_Сыры']].sum(axis=1)\n",
        "df = df.drop(columns=['cnt_checks_6_Сыры','cnt_checks_7_Сыры', 'cnt_checks_8_Сыры', 'cnt_checks_9_Сыры', 'cnt_checks_10_Сыры', 'cnt_checks_11_Сыры', 'cnt_checks_12_Сыры'])\n",
        "\n",
        "df = df.drop(columns=['client_id', 'rto_stddev_Рыба и рыбные изделия', 'rto_Рыба и рыбные изделия', 'cnt_checks_Рыба и рыбные изделия'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AujQalHu-2Vz"
      },
      "source": [
        "We updated dataset to work like sum of all coif's from table for period of time. That helped us to minify unnecessary data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJfQLZrC_SxW"
      },
      "source": [
        "## Estimates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYo6jzNm_VH3"
      },
      "source": [
        "### Inner Estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWYMWyKP_XQP"
      },
      "source": [
        "We decided to split dataset on several sets, so for that we used the most perspective classifier - `Bagging Classifier` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkm1yiWZ_lw5",
        "outputId": "3cbfef62-45d3-4c58-8ffd-1162774fa444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;32mInnerEstimate creating..\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "inner_estimate: list = []\n",
        "counter: int = 0\n",
        "\n",
        "print('\\033[1;32mInnerEstimate creating..\\033[0m')\n",
        "\n",
        "for i in range(100):\n",
        "  inner_estimate.append(\n",
        "    tuple([f'in_est-{counter}', rn.choice([BaggingClassifier(), HistGradientBoostingClassifier()])])\n",
        "  )\n",
        "  counter += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsTz0NtgBUIr"
      },
      "source": [
        "After that we orginized data for X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAIjQOXU_oyq"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['is_in_club'])\n",
        "y = df['is_in_club']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdfbDnBZDpn2"
      },
      "source": [
        "And only after that we started learning them, turning whole classificators into cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXnxW_qaDqXi",
        "outputId": "dd0a91c0-4a8d-45b7-e7f3-b60e029a1a06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Machine id is: in_est-0\n",
            "in_est-0 - Accurancy is: 0.9081755045830804\n",
            "in_est-0 - Precision is: 0.5434782608695652\n",
            "in_est-0 - Recall is: 0.008052826542116283\n",
            "in_est-0 - F1-Score is: 0.01587049674654817\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-1\n",
            "in_est-1 - Accurancy is: 0.9082051206112748\n",
            "in_est-1 - Precision is: 0.5595238095238095\n",
            "in_est-1 - Recall is: 0.007569656949589306\n",
            "in_est-1 - F1-Score is: 0.01493723184490704\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-2\n",
            "in_est-2 - Accurancy is: 0.9045327331151619\n",
            "in_est-2 - Precision is: 0.3218562874251497\n",
            "in_est-2 - Recall is: 0.03462715413110001\n",
            "in_est-2 - F1-Score is: 0.06252726479569579\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-3\n",
            "in_est-3 - Accurancy is: 0.9044883090728703\n",
            "in_est-3 - Precision is: 0.30082644628099175\n",
            "in_est-3 - Recall is: 0.029312288613303268\n",
            "in_est-3 - F1-Score is: 0.05341943058409158\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-4\n",
            "in_est-4 - Accurancy is: 0.9046363892138425\n",
            "in_est-4 - Precision is: 0.2991304347826087\n",
            "in_est-4 - Recall is: 0.027701723304880015\n",
            "in_est-4 - F1-Score is: 0.05070754716981132\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-5\n",
            "in_est-5 - Accurancy is: 0.9080570404703026\n",
            "in_est-5 - Precision is: 0.5\n",
            "in_est-5 - Recall is: 0.008697052665485585\n",
            "in_est-5 - F1-Score is: 0.01709672312806712\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-6\n",
            "in_est-6 - Accurancy is: 0.9041477247486339\n",
            "in_est-6 - Precision is: 0.2870967741935484\n",
            "in_est-6 - Recall is: 0.028668062489933966\n",
            "in_est-6 - F1-Score is: 0.05213061941719139\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-7\n",
            "in_est-7 - Accurancy is: 0.9046956212702314\n",
            "in_est-7 - Precision is: 0.3046471600688468\n",
            "in_est-7 - Recall is: 0.02850700595909164\n",
            "in_est-7 - F1-Score is: 0.05213549337260677\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-8\n",
            "in_est-8 - Accurancy is: 0.9080422324562053\n",
            "in_est-8 - Precision is: 0.4953271028037383\n",
            "in_est-8 - Recall is: 0.00853599613464326\n",
            "in_est-8 - F1-Score is: 0.01678277390753642\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-9\n",
            "in_est-9 - Accurancy is: 0.9047696613407176\n",
            "in_est-9 - Precision is: 0.3072916666666667\n",
            "in_est-9 - Recall is: 0.02850700595909164\n",
            "in_est-9 - F1-Score is: 0.052173913043478265\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-10\n",
            "in_est-10 - Accurancy is: 0.9076868401178718\n",
            "in_est-10 - Precision is: 0.4161073825503356\n",
            "in_est-10 - Recall is: 0.009985504912224191\n",
            "in_est-10 - F1-Score is: 0.019502988361119848\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-11\n",
            "in_est-11 - Accurancy is: 0.9080570404703026\n",
            "in_est-11 - Precision is: 0.5\n",
            "in_est-11 - Recall is: 0.006603317764535352\n",
            "in_est-11 - F1-Score is: 0.013034493721188999\n",
            "\n",
            "\n",
            "--------------------\n",
            "Machine id is: in_est-12\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, 100):\n",
        "  # Debug print\n",
        "  print(f'--------------------\\nMachine id is: {inner_estimate[i][0]}')\n",
        "\n",
        "  # Getting specified data\n",
        "  X = df.drop(columns=[\n",
        "     rn.choice(['rto_Крупы и зерновые', 'rto_Мясная гастрономия',\n",
        "                'rto_Овощи - Фрукты', 'rto_Птица и изделия из птицы',\n",
        "                'rto_Сыры']),\n",
        "\n",
        "     rn.choice(['rto_stddev_Крупы и зерновые', 'rto_stddev_Мясная гастрономия',\n",
        "                'rto_stddev_Овощи - Фрукты', 'rto_stddev_Птица и изделия из птицы',\n",
        "                'rto_stddev_Сыры']),\n",
        "\n",
        "     rn.choice(['cnt_checks_Крупы и зерновые', 'cnt_checks_Мясная гастрономия',\n",
        "                'cnt_checks_Овощи - Фрукты', 'cnt_checks_Птица и изделия из птицы', 'cnt_checks_Сыры']),\n",
        "     'is_in_club'\n",
        "  ])\n",
        "  y = df['is_in_club']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state = 2020, stratify=y)\n",
        "\n",
        "  # Learning them \n",
        "  inner_estimate[i][1].fit(X_train, y_train)\n",
        "  y_pred = inner_estimate[i][1].predict(X_test)\n",
        "  y_pred_log_reg = inner_estimate[i][1].predict_proba(X_test)\n",
        "\n",
        "  print(f'{inner_estimate[i][0]} - Accurancy is: {accuracy_score(y_test, y_pred)}')\n",
        "  print(f'{inner_estimate[i][0]} - Precision is: {precision_score(y_test, y_pred)}')\n",
        "  print(f'{inner_estimate[i][0]} - Recall is: {recall_score(y_test, y_pred)}')\n",
        "  print(f'{inner_estimate[i][0]} - F1-Score is: {f1_score(y_test, y_pred)}\\n\\n')\n",
        "\n",
        "  counter += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnqrZGYOOf4y"
      },
      "source": [
        "How does it works\n",
        "\n",
        "After startup, code will first of all, select random columns to drop. It starts learning on different datasets. We doesn't understand how to proved to them slice of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ugg3cdGTP79"
      },
      "source": [
        "### Unstable estimates\n",
        "\n",
        "For working with more fluid data We used unstable models. They working like `what if` selectors and included in main estimate in one item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE4hjRN-Tp8-"
      },
      "outputs": [],
      "source": [
        "unstable_estimate: list = []\n",
        "counter: int = 0\n",
        "\n",
        "#\n",
        "for i in range(20):\n",
        "    unstable_estimate.append(tuple([f'unstable_est-{counter}', rn.choice([\n",
        "       BaggingClassifier(\n",
        "        n_estimators=10, n_jobs=rn.randint(1, 10),\n",
        "        random_state=rn.randint(0, 40)\n",
        "        ),\n",
        "\n",
        "       HistGradientBoostingClassifier(\n",
        "        learning_rate=float(rn.randint(1, 10))\n",
        "        )])\n",
        "    ]))\n",
        "\n",
        "    counter += 1\n",
        "    print('\\033[1;33mAppended unstable_estimate\\033[0m')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etKL1o03WJZS"
      },
      "source": [
        "We dont learned them for work. Reason is that they must be so ustable, so every decision they made must be unique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pabt04l7Qg2j"
      },
      "source": [
        "## Buildin\n",
        "\n",
        "Main estimate that will be included in main Classifier сostructs through using inner estimate and sever classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj_YcQB6QgQ0"
      },
      "outputs": [],
      "source": [
        "estimate_final:list = [\n",
        "      tuple(['m_est-0', BaggingClassifier()]),\n",
        "      tuple(['m_est-1', HistGradientBoostingClassifier()]),\n",
        "      tuple(['m_cmx_est-1', VotingClassifier(inner_estimate.copy(), voting=\"soft\")]),\n",
        "      tuple(['m_cmx_est-2', VotingClassifier(inner_estimate.copy(), voting=\"soft\")]),\n",
        "      tuple(['m_cmx_un_est-1', VotingClassifier(unstable_estimate.copy(), voting=\"soft\")]),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4jSg6_3SuXI"
      },
      "source": [
        "Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZf6PL23SwmS"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['is_in_club'])\n",
        "y = df['is_in_club']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8qYee9hSdUx"
      },
      "source": [
        "Constructing main VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cuh_dMjMD2-W",
        "outputId": "e38cb2d1-9896-4d76-8159-bcac4b6e2185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;32mStating learning..\u001b[0m\n",
            "\u001b[1;32mPredictions..\u001b[0m\n",
            "\u001b[1;32mProbe..\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 42, stratify=y)\n",
        "\n",
        "mch = VotingClassifier(estimators=estimate_final, voting='soft')\n",
        "print('\\033[1;32mStating learning..\\033[0m')\n",
        "mch.fit(X_train, y_train)\n",
        "print('\\033[1;32mPredictions..\\033[0m')\n",
        "y_pred = mch.predict(X_test)\n",
        "print('\\033[1;32mProbe..\\033[0m')\n",
        "y_pred_log_reg = mch.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heqiIG9YTAdX"
      },
      "source": [
        "And getting accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3yH18zpOTCky",
        "outputId": "6e3512b4-7ae9-40a3-c451-6b62a741aa49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.908117179594758\n",
            "Precision: 0.52\n",
            "Recall: 0.00697986577181208\n",
            "F1-Score: 0.013774834437086093\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}